{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Num_Vehicles'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Num_Vehicles'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 111\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[0;32m    110\u001b[0m env \u001b[38;5;241m=\u001b[39m FleetEnv(df)\n\u001b[1;32m--> 111\u001b[0m dqn_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 68\u001b[0m, in \u001b[0;36mtrain_dqn\u001b[1;34m(env, episodes)\u001b[0m\n\u001b[0;32m     65\u001b[0m epsilon_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episodes):\n\u001b[1;32m---> 68\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     total_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m, in \u001b[0;36mFleetEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 34\u001b[0m, in \u001b[0;36mFleetEnv.get_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     33\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step]\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNum_Vehicles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCost ($)\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcarbon_er\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuel_costs\u001b[39m\u001b[38;5;124m\"\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Num_Vehicles'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data\\something_new.csv\")\n",
    "# df = df[df[\"Year\"] == 2023]  # Filter for Year 2023\n",
    "\n",
    "# Define Action Space: 0 -> Buy, 1 -> Sell, 2 -> Use\n",
    "ACTIONS = [\"Buy\", \"Sell\", \"Use\"]\n",
    "\n",
    "# Define Environment\n",
    "class FleetEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(FleetEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.current_step = 0\n",
    "        self.state_size = 4  # Num_Vehicles, Cost, Emissions, Fuel Cost\n",
    "        self.action_space = gym.spaces.Discrete(len(ACTIONS))  \n",
    "        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(self.state_size,), dtype=np.float32)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self.get_state()\n",
    "\n",
    "    def get_state(self):\n",
    "        row = self.data.iloc[self.current_step]\n",
    "        return np.array([row[\"Num_Vehicles\"], row[\"Cost ($)\"], row[\"carbon_er\"], row[\"fuel_costs\"]], dtype=np.float32)\n",
    "    \n",
    "    def step(self, action):\n",
    "        row = self.data.iloc[self.current_step]\n",
    "        reward = - (row[\"carbon_er\"] + row[\"Cost ($)\"])  # Minimize cost & emissions\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "        self.current_step += 1\n",
    "        return self.get_state(), reward, done, {}\n",
    "\n",
    "# Define DQN Network\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Training Loop\n",
    "def train_dqn(env, episodes=1000):\n",
    "    model = DQN(env.state_size, env.action_space.n)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    memory = deque(maxlen=10000)\n",
    "    gamma = 0.95  # Discount factor\n",
    "    epsilon = 1.0  # Exploration rate\n",
    "    epsilon_decay = 0.995\n",
    "    epsilon_min = 0.01\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            if random.random() < epsilon:\n",
    "                action = env.action_space.sample()  # Explore\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    action = torch.argmax(model(torch.tensor(state, dtype=torch.float32))).item()  # Exploit\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.append((state, action, reward, next_state, done))\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "            if len(memory) > 32:  # Train after 32 experiences\n",
    "                batch = random.sample(memory, 32)\n",
    "                states, actions, rewards, next_states, dones = zip(*batch)\n",
    "                states = torch.tensor(states, dtype=torch.float32)\n",
    "                actions = torch.tensor(actions, dtype=torch.int64).unsqueeze(1)\n",
    "                rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "                next_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "                dones = torch.tensor(dones, dtype=torch.float32)\n",
    "\n",
    "                q_values = model(states).gather(1, actions).squeeze()\n",
    "                next_q_values = model(next_states).max(1)[0].detach()\n",
    "                targets = rewards + gamma * next_q_values * (1 - dones)\n",
    "\n",
    "                loss = loss_fn(q_values, targets)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        epsilon = max(epsilon * epsilon_decay, epsilon_min)  # Decay epsilon\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Run training\n",
    "env = FleetEnv(df)\n",
    "dqn_model = train_dqn(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "     -------------------------------------- 721.7/721.7 kB 7.6 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting gym_notices>=0.0.4\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from gym) (1.23.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from gym) (2.0.0)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827704 sha256=8bc7ebfe1975b0376e27d254eee35125cada3246a4f6605a356cd1734e2cd7ee\n",
      "  Stored in directory: c:\\users\\hjain\\appdata\\local\\pip\\cache\\wheels\\ae\\5f\\67\\64914473eb34e9ba89dbc7eefe7e9be8f6673fbc6f0273b29f\n",
      "Successfully built gym\n",
      "Installing collected packages: gym_notices, gym\n",
      "Successfully installed gym-0.26.2 gym_notices-0.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hjain\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The algorithm only supports (<class 'gymnasium.spaces.discrete.Discrete'>,) as action spaces but MultiDiscrete([50 50 50 50 50]) was provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m env \u001b[38;5;241m=\u001b[39m FleetEnv()\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Train RL model\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDQN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMlpPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Find optimal fleet\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:104\u001b[0m, in \u001b[0;36mDQN.__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, target_update_interval, exploration_fraction, exploration_initial_eps, exploration_final_eps, max_grad_norm, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     78\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m[DQNPolicy]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     _init_setup_model: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    103\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# No action noise\u001b[39;49;00m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_support\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDiscrete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_initial_eps \u001b[38;5;241m=\u001b[39m exploration_initial_eps\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_final_eps \u001b[38;5;241m=\u001b[39m exploration_final_eps\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:110\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, use_sde_at_warmup, sde_support, supported_action_spaces)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     82\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m[BasePolicy]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     supported_action_spaces: Optional[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtype\u001b[39m[spaces\u001b[38;5;241m.\u001b[39mSpace], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ):\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupport_multi_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupported_action_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size \u001b[38;5;241m=\u001b[39m buffer_size\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:181\u001b[0m, in \u001b[0;36mBaseAlgorithm.__init__\u001b[1;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vec_normalize_env \u001b[38;5;241m=\u001b[39m unwrap_vec_normalize(env)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m supported_action_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, supported_action_spaces), (\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe algorithm only supports \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_action_spaces\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as action spaces \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was provided\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    184\u001b[0m     )\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m support_multi_env \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_envs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: the model does not support multiple envs; it requires \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma single vectorized environment.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: The algorithm only supports (<class 'gymnasium.spaces.discrete.Discrete'>,) as action spaces but MultiDiscrete([50 50 50 50 50]) was provided"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "# Load CSV data\n",
    "df = pd.read_csv(\"data\\something_new.csv\")  # Replace with your actual file path\n",
    "# df = df[df['Year'] == 2023]  # Filter for 2023 only\n",
    "\n",
    "# Define vehicle types\n",
    "vehicle_types = df['Fuel'].unique()\n",
    "costs = df.groupby('Fuel')['Cost ($)'].mean().to_dict()\n",
    "emissions = df.groupby('Fuel')['carbon_emissions'].mean().to_dict()\n",
    "\n",
    "# Constraints\n",
    "MAX_EMISSIONS = 11677957  # Given limit\n",
    "NUM_VEHICLE_TYPES = len(vehicle_types)\n",
    "\n",
    "class FleetEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(FleetEnv, self).__init__()\n",
    "        \n",
    "        # Action space: Number of vehicles per type\n",
    "        self.action_space = spaces.MultiDiscrete([50] * NUM_VEHICLE_TYPES)  # Up to 50 per type\n",
    "        \n",
    "        # Observation space: Current fleet composition\n",
    "        self.observation_space = spaces.Box(low=0, high=50, shape=(NUM_VEHICLE_TYPES,), dtype=np.int32)\n",
    "        \n",
    "        self.state = np.zeros(NUM_VEHICLE_TYPES)\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.state = action\n",
    "        total_emission = sum(self.state[i] * emissions[vehicle_types[i]] for i in range(NUM_VEHICLE_TYPES))\n",
    "        total_cost = sum(self.state[i] * costs[vehicle_types[i]] for i in range(NUM_VEHICLE_TYPES))\n",
    "        \n",
    "        # Reward function (penalizes high cost and excess emissions)\n",
    "        reward = -total_cost / 1e6  # Normalize cost penalty\n",
    "        if total_emission > MAX_EMISSIONS:\n",
    "            reward -= 10  # Heavy penalty for exceeding emissions\n",
    "        \n",
    "        done = total_emission <= MAX_EMISSIONS\n",
    "        return self.state, reward, done, {}\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = np.zeros(NUM_VEHICLE_TYPES)\n",
    "        return self.state\n",
    "\n",
    "# Initialize environment\n",
    "env = FleetEnv()\n",
    "\n",
    "# Train RL model\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Find optimal fleet\n",
    "done = False\n",
    "obs = env.reset()\n",
    "while not done:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "\n",
    "print(\"Optimal Fleet Composition:\")\n",
    "for i, vehicle in enumerate(vehicle_types):\n",
    "    print(f\"{vehicle}: {obs[i]} vehicles\")\n",
    "\n",
    "print(f\"Total Cost: ${sum(obs[i] * costs[vehicle_types[i]] for i in range(NUM_VEHICLE_TYPES)):.2f}\")\n",
    "print(f\"Total Emissions: {sum(obs[i] * emissions[vehicle_types[i]] for i in range(NUM_VEHICLE_TYPES)):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable_baselines3\n",
      "  Using cached stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from stable_baselines3) (2.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from stable_baselines3) (1.5.3)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from stable_baselines3) (2.0.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from stable_baselines3) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from stable_baselines3) (3.7.0)\n",
      "Collecting gymnasium<1.1.0,>=0.29.1\n",
      "  Using cached gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
      "Requirement already satisfied: networkx in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable_baselines3) (2.8.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable_baselines3) (2022.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable_baselines3) (3.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (9.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (22.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (4.25.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from pandas->stable_baselines3) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (2.1.1)\n",
      "Installing collected packages: gymnasium, stable_baselines3\n",
      "Successfully installed gymnasium-1.0.0 stable_baselines3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stable_baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shimmy>=2.0\n",
      "  Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from shimmy>=2.0) (1.23.5)\n",
      "Requirement already satisfied: gymnasium>=1.0.0a1 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from shimmy>=2.0) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (2.0.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (0.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.12.2)\n",
      "Installing collected packages: shimmy\n",
      "Successfully installed shimmy-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"shimmy>=2.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "from gym import spaces\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class FleetEnv(gym.Env):\n",
    "    def __init__(self, csv_path):\n",
    "        super(FleetEnv, self).__init__()\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Encode categorical columns\n",
    "        self.label_encoders = {}\n",
    "        for col in ['ID', 'Fuel']:\n",
    "            le = LabelEncoder()\n",
    "            self.df[col] = le.fit_transform(self.df[col])\n",
    "            self.label_encoders[col] = le\n",
    "        \n",
    "        # Define state space (normalized numerical features)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=1, shape=(len(self.df.columns) - 1,), dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Define action space: 3 discrete actions (Buy=0, Use=1, Sell=2)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        \n",
    "        # Internal state tracking\n",
    "        self.current_index = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.current_index = 0\n",
    "        return self._get_observation()\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        obs = self.df.iloc[self.current_index].drop(['Type']).values\n",
    "        obs = obs.astype(np.float32)  # Ensure numeric format\n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        reward = self._calculate_reward(action)\n",
    "        \n",
    "        self.current_index += 1\n",
    "        done = self.current_index >= len(self.df)\n",
    "        \n",
    "        return (self._get_observation() if not done else np.zeros_like(self._get_observation())), reward, done, {}\n",
    "    \n",
    "    def _calculate_reward(self, action):\n",
    "        row = self.df.iloc[self.current_index]\n",
    "        actual_action = {'Buy': 0, 'Use': 1, 'Sell': 2}[row['Type']]\n",
    "        return 1 if action == actual_action else -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hjain\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'BEV_S1_2023'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m env \u001b[38;5;241m=\u001b[39m FleetEnv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/something_new.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m DQN(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:267\u001b[0m, in \u001b[0;36mDQN.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDQN,\n\u001b[0;32m    260\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDQN:\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:314\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfOffPolicyAlgorithm,\n\u001b[0;32m    307\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    313\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfOffPolicyAlgorithm:\n\u001b[1;32m--> 314\u001b[0m     total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must set the environment before calling learn()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:297\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise, VectorizedActionNoise)\n\u001b[0;32m    294\u001b[0m ):\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise \u001b[38;5;241m=\u001b[39m VectorizedActionNoise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:424\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_num_timesteps \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_episode_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;66;03m# Retrieve unnormalized observation for saving into the buffer\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:78\u001b[0m, in \u001b[0;36mDummyVecEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m     77\u001b[0m     maybe_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx]} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx] \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m---> 78\u001b[0m     obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[env_idx]\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds[env_idx], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmaybe_options)\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Seeds and options are only used once\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:83\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\shimmy\\openai_gym_compatibility.py:234\u001b[0m, in \u001b[0;36mGymV21CompatibilityV0.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     warn(\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGym v21 environment do not accept options as a reset parameter, options=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m     )\n\u001b[1;32m--> 234\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgym_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender()\n",
      "Cell \u001b[1;32mIn[10], line 32\u001b[0m, in \u001b[0;36mFleetEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 36\u001b[0m, in \u001b[0;36mFleetEnv._get_observation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_observation\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     35\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_index]\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m---> 36\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[43mobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure numeric format\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obs\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'BEV_S1_2023'"
     ]
    }
   ],
   "source": [
    "env = FleetEnv(\"data/something_new.csv\")\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Demand'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m forecast_demand \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# dict with key: (Size, Distance) -> forecast DataFrame\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (size, bucket), group \u001b[38;5;129;01min\u001b[39;00m demand_df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistance\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Prophet expects columns 'ds' (as datetime) and 'y' (demand value)\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     df_prophet \u001b[38;5;241m=\u001b[39m \u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDemand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDemand\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Convert year to datetime (using Jan 1 as date)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     df_prophet[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_prophet[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hjain\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Demand'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from pulp import LpProblem, LpMinimize, LpVariable, lpSum, LpInteger\n",
    "\n",
    "# ====================\n",
    "# 1. Demand Forecasting\n",
    "# ====================\n",
    "\n",
    "# Assume demand.csv has columns: Year, Size, Distance, Demand (in kms)\n",
    "demand_df = pd.read_csv(\"data/demand.csv\")\n",
    "\n",
    "# Forecast demand per (Size, Distance) combination using Prophet.\n",
    "# We create forecasts for each unique combination.\n",
    "forecast_horizon = list(range(2023, 2039))\n",
    "forecast_demand = {}  # dict with key: (Size, Distance) -> forecast DataFrame\n",
    "\n",
    "for (size, bucket), group in demand_df.groupby([\"Size\", \"Distance\"]):\n",
    "    # Prophet expects columns 'ds' (as datetime) and 'y' (demand value)\n",
    "    df_prophet = group[['Year', 'Demand']].rename(columns={'Year':'ds', 'Demand':'y'})\n",
    "    # Convert year to datetime (using Jan 1 as date)\n",
    "    df_prophet['ds'] = pd.to_datetime(df_prophet['ds'].astype(str) + '-01-01')\n",
    "    model = Prophet(yearly_seasonality=False, daily_seasonality=False)\n",
    "    model.fit(df_prophet)\n",
    "    \n",
    "    # Create dataframe for future predictions from 2023 to 2038\n",
    "    future = pd.DataFrame({'ds': pd.to_datetime([str(year) + '-01-01' for year in forecast_horizon])})\n",
    "    forecast = model.predict(future)\n",
    "    forecast_demand[(size, bucket)] = forecast[['ds', 'yhat']].rename(columns={'ds':'Year'})\n",
    "    forecast_demand[(size, bucket)]['Year'] = forecast_demand[(size, bucket)]['Year'].dt.year\n",
    "\n",
    "# ====================\n",
    "# 2. Fleet Optimization Model Setup\n",
    "# ====================\n",
    "\n",
    "# Load other datasets\n",
    "vehicles_df = pd.read_csv(\"data/vehicles.csv\")  # columns: ID, Vehicle, Size, Year, Cost, Yearly_range, Distance\n",
    "fuels_df = pd.read_csv(\"data/fuels.csv\")        # columns: Fuel, Year, Emissions, Cost, Cost_Uncertainty\n",
    "carbon_limits_df = pd.read_csv(\"data/carbon_emissions.csv\")  # columns: Year, Carbon emission CO2/kg\n",
    "\n",
    "# For simplicity, assume vehicle_fuel consumption and insurance/maintenance/resale details are pre-processed into dictionaries.\n",
    "# e.g. fuel_consumption = { vehicle_ID: { fuel: consumption_value } }\n",
    "# and cost_factors = { 'insurance': {year_offset: percentage}, ... }\n",
    "# (You must create these from your provided tables)\n",
    "\n",
    "# Define indices and sets\n",
    "years = list(range(2023, 2039))\n",
    "vehicles = vehicles_df['ID'].unique()\n",
    "# Assume we have a mapping from vehicle ID to its properties:\n",
    "vehicle_props = vehicles_df.set_index(\"ID\").to_dict(orient=\"index\")\n",
    "\n",
    "# Decision variables:\n",
    "# Let buy[year][vehicle] be the number of vehicles bought in that year of that model.\n",
    "# Similarly, use[year][vehicle] be number of vehicles used, and sell[year][vehicle] be vehicles sold at end of year.\n",
    "buy = {(yr, vid): LpVariable(f\"buy_{yr}_{vid}\", lowBound=0, cat=LpInteger)\n",
    "       for yr in years for vid in vehicles if vehicle_props[vid]['Year'] == yr}\n",
    "use = {(yr, vid): LpVariable(f\"use_{yr}_{vid}\", lowBound=0, cat=LpInteger)\n",
    "       for yr in years for vid in vehicles}  # usage decision (should not exceed fleet available)\n",
    "sell = {(yr, vid): LpVariable(f\"sell_{yr}_{vid}\", lowBound=0, cat=LpInteger)\n",
    "        for yr in years for vid in vehicles}\n",
    "\n",
    "# For assigning vehicles to meet demand, define an allocation variable:\n",
    "# alloc[year][(size, demand_bucket)][vehicle] = number of vehicles of a given model used to satisfy demand in that bucket.\n",
    "alloc = {(yr, s, d, vid): LpVariable(f\"alloc_{yr}_{s}_{d}_{vid}\", lowBound=0, cat=LpInteger)\n",
    "         for yr in years\n",
    "         for (s, d) in forecast_demand.keys()\n",
    "         for vid in vehicles if vehicle_props[vid]['Size'] == s}\n",
    "\n",
    "# Create the LP problem:\n",
    "prob = LpProblem(\"Fleet_Optimization\", LpMinimize)\n",
    "\n",
    "# ===============\n",
    "# 3. Objective Function\n",
    "# ===============\n",
    "# The total cost includes purchase, insurance, maintenance, fuel and subtracting resale.\n",
    "# Here we only include purchase cost as an example. You should add the others similarly.\n",
    "purchase_cost = lpSum(buy[(yr, vid)] * vehicle_props[vid]['Cost'] for (yr, vid) in buy)\n",
    "# For resale, assume a simple factor based on vehicle age – placeholder.\n",
    "resale_value = lpSum(sell[(yr, vid)] * 0.3 * vehicle_props[vid]['Cost']\n",
    "                     for (yr, vid) in sell)\n",
    "# Define a placeholder fuel cost term (to be replaced by actual calculations based on fuel consumption, distance allocated, and fuel cost):\n",
    "fuel_cost = lpSum(alloc[(yr, s, d, vid)] * 0.5   # placeholder per km cost\n",
    "                  for (yr, s, d, vid) in alloc)\n",
    "\n",
    "prob += (purchase_cost + fuel_cost - resale_value), \"Total_Fleet_Cost\"\n",
    "\n",
    "# ===============\n",
    "# 4. Constraints\n",
    "# ===============\n",
    "\n",
    "# Constraint 1: Demand satisfaction – For every year and (size, distance) bucket,\n",
    "# the sum of distance covered by vehicles allocated must exceed the forecasted demand.\n",
    "for (s, d), df_forecast in forecast_demand.items():\n",
    "    for yr in years:\n",
    "        # get forecasted demand for this combination and year (if available)\n",
    "        demand_val = df_forecast.loc[df_forecast['Year'] == yr, 'yhat']\n",
    "        if not demand_val.empty:\n",
    "            # Each vehicle has a maximum daily distance given in vehicles.csv under \"Distance\" mapping.\n",
    "            # We assume a conversion: for a vehicle with distance bucket D, the maximum distance is defined in vehicle_props.\n",
    "            prob += (lpSum(alloc[(yr, s, d, vid)] * vehicle_props[vid]['Yearly_range']\n",
    "                           for vid in vehicles if vehicle_props[vid]['Size'] == s)\n",
    "                     >= float(demand_val), f\"Demand_{yr}_{s}_{d}\")\n",
    "\n",
    "# Constraint 2: A vehicle’s distance bucket – vehicles can only satisfy demands for buckets less than or equal to their own.\n",
    "for yr in years:\n",
    "    for (s, d), _ in forecast_demand.items():\n",
    "        for vid in vehicles:\n",
    "            if vehicle_props[vid]['Size'] == s:\n",
    "                # Let vehicle_distance = vehicle_props[vid]['Distance'] (like D3)\n",
    "                # If vehicle's bucket < current demand bucket d, then allocation must be zero.\n",
    "                # (Here we use a simple mapping of bucket order; you must implement the actual logic.)\n",
    "                vehicle_bucket = vehicle_props[vid]['Distance']\n",
    "                bucket_order = {'D1': 1, 'D2': 2, 'D3': 3, 'D4': 4}\n",
    "                if bucket_order[vehicle_bucket] < bucket_order[d]:\n",
    "                    prob += (alloc[(yr, s, d, vid)] == 0, f\"Distance_{yr}_{s}_{d}_{vid}\")\n",
    "\n",
    "# Constraint 3: Fleet availability and lifetime\n",
    "# For each year and vehicle, the number used must not exceed those bought minus those sold, taking into account lifetime limits.\n",
    "fleet = {}\n",
    "for vid in vehicles:\n",
    "    for yr in years:\n",
    "        # Sum over all years of purchase that are still active\n",
    "        active_fleet = lpSum(buy[(y, vid)] for y in years if y <= yr and yr - y < 10) - \\\n",
    "                       lpSum(sell[(y, vid)] for y in years if y < yr)\n",
    "        fleet[(yr, vid)] = active_fleet\n",
    "        prob += (use[(yr, vid)] <= active_fleet, f\"Fleet_use_{yr}_{vid}\")\n",
    "\n",
    "# Constraint 4: Selling limits – at most 20% of the fleet can be sold in any year.\n",
    "for yr in years:\n",
    "    total_fleet = lpSum(fleet[(yr, vid)] for vid in vehicles)\n",
    "    total_sell = lpSum(sell[(yr, vid)] for vid in vehicles)\n",
    "    prob += (total_sell <= 0.20 * total_fleet, f\"Sell_limit_{yr}\")\n",
    "\n",
    "# Constraint 5: A vehicle model can only be bought in its designated year.\n",
    "for (yr, vid) in buy:\n",
    "    model_year = vehicle_props[vid]['Year']\n",
    "    if yr != model_year:\n",
    "        prob += (buy[(yr, vid)] == 0, f\"Purchase_year_{yr}_{vid}\")\n",
    "\n",
    "# Constraint 6: Linking allocation with usage – you cannot allocate more vehicles than available.\n",
    "for yr in years:\n",
    "    for vid in vehicles:\n",
    "        # Sum of allocations of vehicle vid across all demand buckets for its size should be <= use[yr, vid]\n",
    "        relevant_alloc = lpSum(alloc[(yr, s, d, vid)] for (s, d) in forecast_demand.keys() if vehicle_props[vid]['Size'] == s)\n",
    "        prob += (relevant_alloc <= use[(yr, vid)], f\"Allocation_use_{yr}_{vid}\")\n",
    "\n",
    "# Constraint 7: Carbon emissions constraint\n",
    "# (A detailed emission calculation using fuel consumption, distance, and fuel emission factors should be added.)\n",
    "for yr in years:\n",
    "    # For each vehicle allocation, calculate emission: sum over fuel types if needed.\n",
    "    # Here we add a placeholder constraint ensuring total emission cost is below the limit.\n",
    "    total_emission = lpSum(alloc[(yr, s, d, vid)] * 0.2  # placeholder emission per km\n",
    "                            for (s, d) in forecast_demand.keys() \n",
    "                            for vid in vehicles if vehicle_props[vid]['Size'] == s)\n",
    "    carbon_limit = float(carbon_limits_df.loc[carbon_limits_df['Year'] == yr, 'Carbon emission CO2/kg'])\n",
    "    prob += (total_emission <= carbon_limit, f\"Carbon_limit_{yr}\")\n",
    "\n",
    "# [Additional constraints]\n",
    "# • Insurance, maintenance and depreciation calculations per vehicle lifetime\n",
    "# • Constraint that vehicles must be sold within 10 years of purchase\n",
    "# • Fuel type matching with vehicle (ensuring correct fuel usage)\n",
    "# • Demand segmentation per vehicle size and distance buckets\n",
    "# You must similarly add constraints (using your provided percentages and rules) to capture all details.\n",
    "\n",
    "# ====================\n",
    "# 5. Solve the Model\n",
    "# ====================\n",
    "\n",
    "print(\"Starting optimization...\")\n",
    "prob.solve()\n",
    "print(\"Optimization complete. Status:\", prob.status)\n",
    "\n",
    "# ====================\n",
    "# 6. Extract and Save Results\n",
    "# ====================\n",
    "\n",
    "results = []\n",
    "for yr in years:\n",
    "    for vid in vehicles:\n",
    "        b = buy.get((yr, vid))\n",
    "        u = use.get((yr, vid))\n",
    "        s = sell.get((yr, vid))\n",
    "        if b is not None and b.varValue and b.varValue > 0:\n",
    "            results.append({'Year': yr, 'ID': vid, 'Num_Vehicles': int(b.varValue), 'Type': 'Buy', 'Fuel': None,\n",
    "                            'Distance': vehicle_props[vid]['Distance'],\n",
    "                            'Distance_per_vehicle(km)': vehicle_props[vid]['Yearly_range']})\n",
    "        if u is not None and u.varValue and u.varValue > 0:\n",
    "            results.append({'Year': yr, 'ID': vid, 'Num_Vehicles': int(u.varValue), 'Type': 'Use', 'Fuel': None,\n",
    "                            'Distance': vehicle_props[vid]['Distance'],\n",
    "                            'Distance_per_vehicle(km)': vehicle_props[vid]['Yearly_range']})\n",
    "        if s is not None and s.varValue and s.varValue > 0:\n",
    "            results.append({'Year': yr, 'ID': vid, 'Num_Vehicles': int(s.varValue), 'Type': 'Sell', 'Fuel': None,\n",
    "                            'Distance': vehicle_props[vid]['Distance'],\n",
    "                            'Distance_per_vehicle(km)': vehicle_props[vid]['Yearly_range']})\n",
    "                            \n",
    "# Also include allocations per demand bucket if needed\n",
    "alloc_results = []\n",
    "for (yr, s, d, vid), var in alloc.items():\n",
    "    if var.varValue and var.varValue > 0:\n",
    "        alloc_results.append({'Year': yr, 'ID': vid, 'Num_Vehicles': int(var.varValue),\n",
    "                              'Type': 'Use', 'Fuel': None, 'Distance': d,\n",
    "                              'Distance_per_vehicle(km)': vehicle_props[vid]['Yearly_range']})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "alloc_df = pd.DataFrame(alloc_results)\n",
    "\n",
    "# Save results to csv\n",
    "results_df.to_csv(\"fleet_operations.csv\", index=False)\n",
    "alloc_df.to_csv(\"demand_allocation.csv\", index=False)\n",
    "\n",
    "print(\"Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:28:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:28:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization...\n",
      "Optimization complete. Status: 1\n",
      "Results saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from pulp import LpProblem, LpMinimize, LpVariable, lpSum, LpInteger\n",
    "\n",
    "# ====================\n",
    "# 1. Demand Forecasting\n",
    "# ====================\n",
    "\n",
    "# Read demand.csv with headers: Year, Size, Distance, Demand (km)\n",
    "demand_df = pd.read_csv(\"data/demand.csv\")\n",
    "\n",
    "# Forecast demand per (Size, Distance) combination using Prophet.\n",
    "forecast_horizon = list(range(2023, 2039))\n",
    "forecast_demand = {}  # dict with key: (Size, Distance) -> forecast DataFrame\n",
    "\n",
    "for (size, distance), group in demand_df.groupby([\"Size\", \"Distance\"]):\n",
    "    # Use 'Year' as date and 'Demand (km)' as the demand value\n",
    "    df_prophet = group[['Year', 'Demand (km)']].rename(columns={'Year': 'ds', 'Demand (km)': 'y'})\n",
    "    # Convert year to datetime (using Jan 1 as date)\n",
    "    df_prophet['ds'] = pd.to_datetime(df_prophet['ds'].astype(str) + '-01-01')\n",
    "    \n",
    "    model = Prophet(yearly_seasonality=False, daily_seasonality=False)\n",
    "    model.fit(df_prophet)\n",
    "    \n",
    "    # Create dataframe for future predictions from 2023 to 2038\n",
    "    future = pd.DataFrame({'ds': pd.to_datetime([str(year) + '-01-01' for year in forecast_horizon])})\n",
    "    forecast = model.predict(future)\n",
    "    forecast_df = forecast[['ds', 'yhat']].rename(columns={'ds': 'Year'})\n",
    "    forecast_df['Year'] = forecast_df['Year'].dt.year\n",
    "    forecast_demand[(size, distance)] = forecast_df\n",
    "\n",
    "# ====================\n",
    "# 2. Fleet Optimization Model Setup\n",
    "# ====================\n",
    "\n",
    "# Load other datasets\n",
    "vehicles_df = pd.read_csv(\"data/vehicles.csv\")  # columns: ID, Vehicle, Size, Year, Cost, Yearly_range, Distance\n",
    "fuels_df = pd.read_csv(\"data/fuels.csv\")        # columns: Fuel, Year, Emissions, Cost, Cost_Uncertainty\n",
    "carbon_limits_df = pd.read_csv(\"data/carbon_emissions.csv\")  # columns: Year, Carbon emission CO2/kg\n",
    "\n",
    "# Assume vehicle fuel consumption, insurance, maintenance, etc. are pre-processed as needed.\n",
    "# Define indices and sets\n",
    "years = list(range(2023, 2039))\n",
    "vehicles = vehicles_df['ID'].unique()\n",
    "vehicle_props = vehicles_df.set_index(\"ID\").to_dict(orient=\"index\")\n",
    "\n",
    "# Decision variables:\n",
    "# buy[year, vehicle] = number of vehicles bought in that year for that model (only if model year equals that year)\n",
    "buy = {(yr, vid): LpVariable(f\"buy_{yr}_{vid}\", lowBound=0, cat=LpInteger)\n",
    "       for yr in years for vid in vehicles if vehicle_props[vid]['Year'] == yr}\n",
    "# use[year, vehicle] = number of vehicles used in that year (should not exceed fleet available)\n",
    "use = {(yr, vid): LpVariable(f\"use_{yr}_{vid}\", lowBound=0, cat=LpInteger)\n",
    "       for yr in years for vid in vehicles}\n",
    "# sell[year, vehicle] = vehicles sold at end of that year\n",
    "sell = {(yr, vid): LpVariable(f\"sell_{yr}_{vid}\", lowBound=0, cat=LpInteger)\n",
    "        for yr in years for vid in vehicles}\n",
    "\n",
    "# Allocation: assign vehicles to meet demand for each (Size, Distance) bucket\n",
    "alloc = {(yr, s, d, vid): LpVariable(f\"alloc_{yr}_{s}_{d}_{vid}\", lowBound=0, cat=LpInteger)\n",
    "         for yr in years\n",
    "         for (s, d) in forecast_demand.keys()\n",
    "         for vid in vehicles if vehicle_props[vid]['Size'] == s}\n",
    "\n",
    "# Create the LP problem:\n",
    "prob = LpProblem(\"Fleet_Optimization\", LpMinimize)\n",
    "\n",
    "# ===============\n",
    "# 3. Objective Function\n",
    "# ===============\n",
    "purchase_cost = lpSum(buy[(yr, vid)] * vehicle_props[vid]['Cost'] for (yr, vid) in buy)\n",
    "resale_value = lpSum(sell[(yr, vid)] * 0.3 * vehicle_props[vid]['Cost']\n",
    "                     for (yr, vid) in sell)\n",
    "fuel_cost = lpSum(alloc[(yr, s, d, vid)] * 0.5  # placeholder cost per km\n",
    "                  for (yr, s, d, vid) in alloc)\n",
    "\n",
    "prob += (purchase_cost + fuel_cost - resale_value), \"Total_Fleet_Cost\"\n",
    "\n",
    "# ===============\n",
    "# 4. Constraints\n",
    "# ===============\n",
    "\n",
    "# Constraint 1: Demand satisfaction for each (Size, Distance) bucket and year\n",
    "for (s, d), df_forecast in forecast_demand.items():\n",
    "    for yr in years:\n",
    "        demand_val = df_forecast.loc[df_forecast['Year'] == yr, 'yhat']\n",
    "        if not demand_val.empty:\n",
    "            prob += (lpSum(alloc[(yr, s, d, vid)] * vehicle_props[vid]['Yearly_range']\n",
    "                           for vid in vehicles if vehicle_props[vid]['Size'] == s)\n",
    "                     >= float(demand_val), f\"Demand_{yr}_{s}_{d}\")\n",
    "\n",
    "# Constraint 2: Distance bucket matching\n",
    "for yr in years:\n",
    "    for (s, d), _ in forecast_demand.items():\n",
    "        for vid in vehicles:\n",
    "            if vehicle_props[vid]['Size'] == s:\n",
    "                vehicle_bucket = vehicle_props[vid]['Distance']\n",
    "                bucket_order = {'D1': 1, 'D2': 2, 'D3': 3, 'D4': 4}\n",
    "                if bucket_order[vehicle_bucket] < bucket_order[d]:\n",
    "                    prob += (alloc[(yr, s, d, vid)] == 0, f\"Distance_{yr}_{s}_{d}_{vid}\")\n",
    "\n",
    "# Constraint 3: Fleet availability and lifetime (10-year life)\n",
    "# fleet = {}\n",
    "# for vid in vehicles:\n",
    "#     for yr in years:\n",
    "#         active_fleet = lpSum(buy[(y, vid)] for y in years if y <= yr and yr - y < 10) - \\\n",
    "#                        lpSum(sell[(y, vid)] for y in years if y < yr)\n",
    "#         fleet[(yr, vid)] = active_fleet\n",
    "#         prob += (use[(yr, vid)] <= active_fleet, f\"Fleet_use_{yr}_{vid}\")\n",
    "\n",
    "\n",
    "# Constraint 3: Fleet availability and lifetime (10-year life)\n",
    "fleet = {}\n",
    "for vid in vehicles:\n",
    "    for yr in years:\n",
    "        active_fleet = lpSum(buy[(y, vid)] for y in years if y <= yr and (y, vid) in buy and yr - y < 10) - \\\n",
    "                       lpSum(sell[(y, vid)] for y in years if y < yr)\n",
    "        fleet[(yr, vid)] = active_fleet\n",
    "        prob += (use[(yr, vid)] <= active_fleet, f\"Fleet_use_{yr}_{vid}\")\n",
    "\n",
    "\n",
    "# Constraint 4: Selling limits – at most 20% of the fleet can be sold in any year.\n",
    "for yr in years:\n",
    "    total_fleet = lpSum(fleet[(yr, vid)] for vid in vehicles)\n",
    "    total_sell = lpSum(sell[(yr, vid)] for vid in vehicles)\n",
    "    prob += (total_sell <= 0.20 * total_fleet, f\"Sell_limit_{yr}\")\n",
    "\n",
    "# Constraint 5: Vehicle model purchase year constraint\n",
    "for (yr, vid) in buy:\n",
    "    if yr != vehicle_props[vid]['Year']:\n",
    "        prob += (buy[(yr, vid)] == 0, f\"Purchase_year_{yr}_{vid}\")\n",
    "\n",
    "# Constraint 6: Linking allocation with usage\n",
    "for yr in years:\n",
    "    for vid in vehicles:\n",
    "        relevant_alloc = lpSum(alloc[(yr, s, d, vid)] for (s, d) in forecast_demand.keys() if vehicle_props[vid]['Size'] == s)\n",
    "        prob += (relevant_alloc <= use[(yr, vid)], f\"Allocation_use_{yr}_{vid}\")\n",
    "\n",
    "# Constraint 7: Carbon emissions constraint (placeholder)\n",
    "for yr in years:\n",
    "    total_emission = lpSum(alloc[(yr, s, d, vid)] * 0.2  # placeholder emission per km\n",
    "                           for (s, d) in forecast_demand.keys() \n",
    "                           for vid in vehicles if vehicle_props[vid]['Size'] == s)\n",
    "    carbon_limit = float(carbon_limits_df.loc[carbon_limits_df['Year'] == yr, 'Carbon emission CO2/kg'])\n",
    "    prob += (total_emission <= carbon_limit, f\"Carbon_limit_{yr}\")\n",
    "\n",
    "# [Additional constraints would go here.]\n",
    "\n",
    "# ====================\n",
    "# 5. Solve the Model\n",
    "# ====================\n",
    "\n",
    "print(\"Starting optimization...\")\n",
    "prob.solve()\n",
    "print(\"Optimization complete. Status:\", prob.status)\n",
    "\n",
    "# ====================\n",
    "# 6. Extract and Save Results\n",
    "# ====================\n",
    "\n",
    "results = []\n",
    "for yr in years:\n",
    "    for vid in vehicles:\n",
    "        b = buy.get((yr, vid))\n",
    "        u = use.get((yr, vid))\n",
    "        s = sell.get((yr, vid))\n",
    "        if b is not None and b.varValue and b.varValue > 0:\n",
    "            results.append({'Year': yr, 'ID': vid, 'Num_Vehicles': int(b.varValue), 'Type': 'Buy', 'Fuel': None,\n",
    "                            'Distance': vehicle_props[vid]['Distance'],\n",
    "                            'Distance_per_vehicle(km)': vehicle_props[vid]['Yearly_range']})\n",
    "        if u is not None and u.varValue and u.varValue > 0:\n",
    "            results.append({'Year': yr, 'ID': vid, 'Num_Vehicles': int(u.varValue), 'Type': 'Use', 'Fuel': None,\n",
    "                            'Distance': vehicle_props[vid]['Distance'],\n",
    "                            'Distance_per_vehicle(km)': vehicle_props[vid]['Yearly_range']})\n",
    "        if s is not None and s.varValue and s.varValue > 0:\n",
    "            results.append({'Year': yr, 'ID': vid, 'Num_Vehicles': int(s.varValue), 'Type': 'Sell', 'Fuel': None,\n",
    "                            'Distance': vehicle_props[vid]['Distance'],\n",
    "                            'Distance_per_vehicle(km)': vehicle_props[vid]['Yearly_range']})\n",
    "\n",
    "alloc_results = []\n",
    "for (yr, s, d, vid), var in alloc.items():\n",
    "    if var.varValue and var.varValue > 0:\n",
    "        alloc_results.append({'Year': yr, 'ID': vid, 'Num_Vehicles': int(var.varValue),\n",
    "                              'Type': 'Use', 'Fuel': None, 'Distance': d,\n",
    "                              'Distance_per_vehicle(km)': vehicle_props[vid]['Yearly_range']})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "alloc_df = pd.DataFrame(alloc_results)\n",
    "\n",
    "results_df.to_csv(\"fleet_operations.csv\", index=False)\n",
    "alloc_df.to_csv(\"demand_allocation.csv\", index=False)\n",
    "\n",
    "print(\"Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prophet\n",
      "  Downloading prophet-1.1.6-py3-none-win_amd64.whl (13.3 MB)\n",
      "     ---------------------------------------- 13.3/13.3 MB 5.4 MB/s eta 0:00:00\n",
      "Collecting holidays<1,>=0.25\n",
      "  Downloading holidays-0.67-py3-none-any.whl (820 kB)\n",
      "     -------------------------------------- 820.7/820.7 kB 7.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from prophet) (1.23.5)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\hjain\\appdata\\roaming\\python\\python310\\site-packages (from prophet) (6.0.1)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from prophet) (1.5.3)\n",
      "Collecting cmdstanpy>=1.0.4\n",
      "  Downloading cmdstanpy-1.2.5-py3-none-any.whl (94 kB)\n",
      "     ---------------------------------------- 94.5/94.5 kB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from prophet) (3.7.0)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from prophet) (4.64.1)\n",
      "Collecting stanio<2.0.0,>=0.4.0\n",
      "  Downloading stanio-0.5.1-py3-none-any.whl (8.1 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from holidays<1,>=0.25->prophet) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (22.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2022.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hjain\\anaconda3\\lib\\site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.16.0)\n",
      "Installing collected packages: stanio, holidays, cmdstanpy, prophet\n",
      "Successfully installed cmdstanpy-1.2.5 holidays-0.67 prophet-1.1.6 stanio-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pulp\n",
      "  Downloading PuLP-3.0.2-py3-none-any.whl (17.7 MB)\n",
      "     ---------------------------------------- 17.7/17.7 MB 5.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pulp\n",
      "Successfully installed pulp-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
